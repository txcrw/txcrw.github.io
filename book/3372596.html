<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><script type="text/javascript" src="https://file.bkxsj.com/skin/book/js/sk.js"></script><meta name="robots" content="index,follow"><title>应用线性回归模型 第4版[PDF|Epub|txt|kindle电子书版本网盘下载]-灵感之桥</title><meta name="Keywords" content="应用线性回归模型 第4版"/><meta name="description" content="应用线性回归模型 第4版pdf下载文件大小为122MB,PDF页数为739页"/><meta http-equiv="X-UA-Compatible" content="IE=9; IE=8; IE=7; IE=EDGE;chrome=1"><link type="image/x-icon" rel="shortcut icon" href="https://www.shukui.net/skin/book/images/favicon.ico"><link type="text/css" rel="stylesheet" href="https://www.shukui.net/skin/book/css/style.css"><style>#main .d-main {margin-left: 0;width: 620px;}.down-btn {animation: myShake 2.5s linear .15s infinite}@keyframes myShake {0%, 66% {transform: translateZ(0)}67%, 73.6%, 83.6%, 93.6%, to {animation-timing-function: cubic-bezier(.215, .61, .355, 1);transform: translateZ(0)}80.3%, 81.4% {animation-timing-function: cubic-bezier(.755, .05, .855, .06);transform: translate3d(0, -4px, 0)}90.3% {animation-timing-function: cubic-bezier(.755, .05, .855, .06);transform: translate3d(0, -2px, 0)}97% {transform: translate3d(0, -.5px, 0)}}.copylink-btn {margin-right: 20px;}.copymd5-btn {margin-bottom: 25px;margin-left: 10px;}</style></head><body><div id="header"><div class="inner"><div class="logo"><a href="/"><img width="103" height="25" alt="灵感之桥"src="https://www.shukui.net/skin/book/images/logo.png"></a></div><div class="search"><form action="/so/search.php" target="_blank"><input type="text" autocomplete="off" id="bdcsMain" name="q" placeholder="书名 / 作者 / 出版社 / ISBN"class="inp-txt"><select class="inp-select" id="datasource" onchange="selectDatasource(this)"><option value="so">主库</option><option value="s">从库</option></select><input type="submit" value="搜索" class="inp-btn"></form></div></div></div><div id="main"><div class="d-main"><div class="tit"><h3>图书介绍</h3></div><h1 class="book-name">应用线性回归模型 第4版PDF|Epub|txt|kindle电子书版本网盘下载</h1><div class="d-info"><div class="b-thumb"><img src="https://www.shukui.net/cover/77/34499006.jpg" alt="应用线性回归模型 第4版"></div><div class="b-info"><ul><li>（美）库特纳等著 著</li><li>出版社： 北京：高等教育出版社</li><li>ISBN：7040163802</li><li>出版时间：2005</li><li>标注页数：702页</li><li>文件大小：122MB</li><li>文件页数：739页</li><li>主题词：线性回归－高等学校－教材－英文</li></ul></div></div><div class="tit"><h3>PDF下载</h3></div><div></br><a style="color:red;" rel="external nofollow" href="https://www.kjlm.net/ebook/3372602.html"target="_blank"><b>点此进入-本书在线PDF格式电子书下载【推荐-云解压-方便快捷】直接下载PDF格式图书。移动端-PC端通用</a></b></br><a class="down-btn" rel="external nofollow" href="https://down.trackerbk.com/bt/45/34499006.torrent"target="_blank">种子下载</a>[BT下载速度快]温馨提示：（请使用BT下载软件FDM进行下载）<a rel="nofollow" href="https://www.freedownloadmanager.org/zh/" target="_blank">软件下载地址页</a><a class="down-btn" rel="external nofollow" href="https://down.p2spdb.com/45/34499006.rar" target="_blank">直链下载</a>[便捷但速度慢]&nbsp;&nbsp;<a style="color:red;" rel="external nofollow" href="https://pdfyl.ertongbook.com/78/34499006.pdf" target="_blank"><b>[在线试读本书]</b></a>&nbsp;&nbsp;<b> <a style="color:red;" rel="external nofollow" href="https://web.jyjl.org/index/recovery.html" target="_blank">[在线获取解压码]</a></b><div class="copymd5-btn"><a href="javascript:copyToClip('2fdea40af790221cbb94841bfaecc512')">点击复制MD5值：2fdea40af790221cbb94841bfaecc512</a></div></div><div class="tit"><h3>下载说明</h3></div><div style="margin:20px 10px"><h2>应用线性回归模型 第4版PDF格式电子书版下载</h2>下载的文件为RAR压缩包。需要使用解压软件进行解压得到PDF格式图书。<br><br><div class="copymd5-btn"><a href="javascript:copyToClip('magnet:?xt=urn:btih:RX6G6JQ2LJW7PBBEDNUSCQM7ICDMHIWK')">点击复制85GB完整离线版磁力链接到迅雷FDM等BT下载工具进行下载</a>&nbsp;&nbsp;<a rel="nofollow" target="_blank">详情点击-查看共享计划</a></div>建议使用BT下载工具Free Download Manager进行下载,简称FDM(免费,没有广告,支持多平台）。本站资源全部打包为BT种子。所以需要使用专业的BT下载软件进行下载。如BitComet qBittorrent uTorrent等BT下载工具。迅雷目前由于本站不是热门资源。不推荐使用！后期资源热门了。安装了迅雷也可以迅雷进行下载！<br><br><b>（文件页数 要大于 标注页数，上中下等多册电子书除外）</b><br><br><p style="color:red;"> <b>注意：本站所有压缩包均有解压码：</b> <a rel="nofollow" target="_blank"><b>点击下载压缩包解压工具</b></a></p></div><div class="tit"><h3>图书目录</h3></div><div id="book-contents"><p>PART ONE SIMPLE LINEAR REGRESSION1</p><p>Chapter 1 Linear Regression with One Predictor Variable2</p><p>1.1 Relations between Variables2</p><p>Functional Relation between Two Variables2</p><p>Statistical Relation between Two Variables3</p><p>1.2 Regression Models and Their Uses5</p><p>Historical Origins5</p><p>Basic Concepts5</p><p>Construction of Regression Models7</p><p>Uses of Regression Analysis8</p><p>Regression and Causality8</p><p>Use of Computers9</p><p>1.3 Simple Linear Regression Model with Distribution of Error Terms Unspecified9</p><p>Formal Statement of Model9</p><p>Important Features of Model9</p><p>Meaning of Regression Parameters11</p><p>Alternative Versions of Regression Model12</p><p>1.4 Data for Regression Analysis12</p><p>Observational Data12</p><p>Experimental Data13</p><p>Completely Randomized Design13</p><p>1.5 Overview of Steps in Regression Analysis13</p><p>1.6 Estimation of Regression Function15</p><p>Method of Least Squares15</p><p>Point Estimation of Mean Response21</p><p>Residuals22</p><p>Properties of Fitted Regression Line23</p><p>1.7 Estimation of Error Terms Variance σ224</p><p>Point Estimator of σ224</p><p>1.8 Normal Error Regression Model26</p><p>Model26</p><p>Estimation of Parameters by Method of Maximum Likelihood27</p><p>Cited References33</p><p>Problems33</p><p>Exercises37</p><p>Projects38</p><p>Chapter 2 Inferences in Regression and Correlation Analysis40</p><p>2.1 Inferences Concerning β140</p><p>Sampling Distribution of b141</p><p>Sampling Distribution of (b1 - β1)/s {b1}44</p><p>Confidence Interval for β145</p><p>Tests Concerning β147</p><p>2.2 Inferences Concerning β048</p><p>Sampling Distribution of b048</p><p>Sampling Distribution of (bo-βo) /s{bo}49</p><p>Confidence Interval for β049</p><p>2.3 Some Considerations on Making Inferences Concerning β0 and β150</p><p>Effects of Departures from Normality50</p><p>Interpretation of Confidence Coefficient and Risks of Errors50</p><p>Spacing of the X Levels50</p><p>Power of Tests50</p><p>2.4 Interval Estimation of E{Yh}52</p><p>Sampling Distribution of Yh52</p><p>Sampling Distribution of(？h-E{Yh})/s{Yh}54</p><p>Confidence Interval for E{Yh}54</p><p>2.5 Prediction of New Observation55</p><p>Prediction Interval for Yh(new) when Parameters Known56</p><p>Prediction Interval for Yh(new) when Parameters Unknown57</p><p>Prediction of Mean of m New Observations for Given Xh60</p><p>2.6 Confidence Band for Regression Line61</p><p>2.7 Analysis of Variance Approach to Regression Analysis63</p><p>Partitioning of Total Sum of Squares63</p><p>Breakdown of Degrees of Freedom66</p><p>Mean Squares66</p><p>Analysis of Variance Table67</p><p>Expected Mean Squares68</p><p>F Test of β1=0 versus β1≠069</p><p>2.8 General Linear Test Approach72</p><p>Full Model72</p><p>Reduced Model72</p><p>Test Statistic73</p><p>Summary73</p><p>2.9 Descriptive Measures of Linear Association between X and Y74</p><p>Coefficient of Determination74</p><p>Limitations of R275</p><p>Coefficient of Correlation76</p><p>2.10 Considerations in Applying Regression Analysis77</p><p>2.11 Normal Correlation Models78</p><p>Distinction between Regression and Correlation Model78</p><p>Bivariate Normal Distribution78</p><p>Conditional Inferences80</p><p>Inferences on Correlation Coefficients83</p><p>Spearman Rank Correlation Coefficient87</p><p>Cited References89</p><p>Problems89</p><p>Exercises97</p><p>Projects98</p><p>Chapter 3 Diagnostics and Remedial Measures100</p><p>3.1 Diagnostics for Predictor Variable100</p><p>3.2 Residuals102</p><p>Properties of Residuals102</p><p>Semistudentized Residuals103</p><p>Departures from Model to Be Studied by Residuals103</p><p>3.3 Diagnostics for Residuals103</p><p>Nonlinearity of Regression Function104</p><p>Nonconstancy of Error Variance107</p><p>Presence of Outliers108</p><p>Nonindependence of Error Terms108</p><p>Nonnormality of Error Terms110</p><p>Omission of Important Predictor Variables112</p><p>Some Final Comments114</p><p>3.4 Overview of Tests Involving Residuals114</p><p>Tests for Randomness114</p><p>Tests for Constancy of Variance115</p><p>Tests for Outliers115</p><p>Tests for Normality115</p><p>3.5 Correlation Test for Normality115</p><p>3.6 Tests for Constancy of Error Variance116</p><p>Brown-Forsythe Test116</p><p>Breusch-Pagan Test118</p><p>3.7 F Test for Lack of Fit119</p><p>Assumptions119</p><p>Notation121</p><p>Full Model121</p><p>Reduced Model123</p><p>Test Statistic123</p><p>ANOVA Table124</p><p>3.8 Overview of Remedial Measures127</p><p>Nonlinearity of Regression Function128</p><p>Nonconstancy of Error Variance128</p><p>Nonindependence of Error Terms128</p><p>Nonnormality of Error Terms128</p><p>Omission of Important Predictor Variables129</p><p>Outlying Observations129</p><p>3.9 Transformations129</p><p>Transformations for Nonlinear Relation Only129</p><p>Transformations for Nonnormality and Unequal Error Variances132</p><p>Box-Cox Transformations134</p><p>3.10 Exploration of Shape of Regression Function137</p><p>Lowess Method138</p><p>Use of Smoothed Curves to Confirm Fitted Regression Function139</p><p>3.11 Case Example—Plutonium Measurement141</p><p>Cited References146</p><p>Problems146</p><p>Exercises151</p><p>Projects152</p><p>Case Studies153</p><p>Chapter 4 Simultaneous Inferences and Other Topics in Regression Analysis154</p><p>4.1 Joint Estimation ofβ0 andβ1154</p><p>Need for Joint Estimation154</p><p>Bonferroni Joint Confidence Intervals155</p><p>4.2 Simultaneous Estimation of Mean Responses157</p><p>Working-Hotelling Procedure158</p><p>Bonferroni Procedure159</p><p>4.3 Simultaneous Prediction Intervals for New Observations160</p><p>4.4 Regression through Origin161</p><p>Model161</p><p>Inferences161</p><p>Important Cautions for Using Regression through Origin164</p><p>4.5 Effects of Measurement Errors165</p><p>Measurement Errors in Y165</p><p>Measurement Errors in X165</p><p>Berkson Model167</p><p>4.6 Inverse Predictions168</p><p>4.7 Choice of X Levels170</p><p>Cited References172</p><p>Problems172</p><p>Exercises175</p><p>Projects175</p><p>Chapter 5 Matrix Approach to Simple Linear Regression Analysis176</p><p>5.1 Matrices176</p><p>Definition of Matrix176</p><p>Square Matrix178</p><p>Vector178</p><p>Transpose178</p><p>Equality of Matrices179</p><p>5.2 Matrix Addition and Subtraction180</p><p>5.3 Matrix Multiplication182</p><p>Multiplication of a Matrix by a Scalar182</p><p>Multiplication of a Matrix by a Matrix182</p><p>5.4 Special Types of Matrices185</p><p>Symmetric Matrix185</p><p>Diagonal Matrix185</p><p>Vector and Matrix with All Elements Unity187</p><p>Zero Vector187</p><p>5.5 Linear Dependence and Rank of Matrix188</p><p>Linear Dependence188</p><p>Rank of Matrix188</p><p>5.6 Inverse of a Matrix189</p><p>Finding the Inverse190</p><p>Uses of Inverse Matrix192</p><p>5.7 Some Basic Results for Matrices193</p><p>5.8 Random Vectors and Matrices193</p><p>Expectation of Random Vector or Matrix193</p><p>Variance-Covariance Matrix of Random Vector194</p><p>Some Basic Results196</p><p>Multivariate Normal Distribution196</p><p>5.9 Simple Linear Regression Model in Matrix Terms197</p><p>5.10 Least Squares Estimation of Regression Parameters199</p><p>Normal Equations199</p><p>Estimated Regression Coefficients200</p><p>5.11 Fitted Values and Residuals202</p><p>Fitted Values202</p><p>Residuals203</p><p>5.12 Analysis of Variance Results204</p><p>Sums of Squares204</p><p>Sums of Squares as Quadratic Forms205</p><p>5.13 Inferences in Regression Analysis206</p><p>Regression Coefficients207</p><p>Mean Response208</p><p>Prediction of New Observation209</p><p>Cited Reference209</p><p>Problems209</p><p>Exercises212</p><p>PART TWO MULTIPLE LINEAR REGRESSION213</p><p>Chapter 6 Multiple Regression Ⅰ214</p><p>6.1 Multiple Regression Models214</p><p>Need for Several Predictor Variables214</p><p>First-Order Model with Two Predictor Variables215</p><p>First-Order Model with More than Two Predictor Variables217</p><p>General Linear Regression Model217</p><p>6.2 General Linear Regression Model in Matrix Terms222</p><p>6.3 Estimation of Regression Coefficients223</p><p>6.4 Fitted Values and Residuals224</p><p>6.5 Analysis of Variance Results225</p><p>Sums of Squares and Mean Squares225</p><p>F Test for Regression Relation226</p><p>Coefficient of Multiple Determination226</p><p>Coefficient of Multiple Correlation227</p><p>6.6 Inferences about Regression Parameters227</p><p>Interval Estimation of βk228</p><p>Tests for βk228</p><p>Joint Inferences228</p><p>6.7 Estimation of Mean Response and Prediction of New Observation229</p><p>Interval Estimation of E{Yh}229</p><p>Confidence Region for Regression Surface229</p><p>Simultaneous Confidence Intervals for Several Mean Responses230</p><p>Prediction of New Observation Yh(new)230</p><p>Prediction of Mean of m New Observations at Xh230</p><p>Predictions of g New Observations231</p><p>Caution about Hidden Extrapolations231</p><p>6.8 Diagnostics and Remedial Measures232</p><p>Scatter Plot Matrix232</p><p>Three-Dimensional Scatter Plots233</p><p>Residual Plots233</p><p>Correlation Test for Normality234</p><p>Brown-Forsythe Test for Constancy of Error Variance234</p><p>Breusch-Pagan Test for Constancy of Error Variance234</p><p>F Test for Lack of Fit235</p><p>Remedial Measures236</p><p>6.9 An Example—Multiple Regression with Two Predictor Variables236</p><p>Setting236</p><p>Basic Calculations237</p><p>Estimated Regression Function240</p><p>Fitted Values and Residuals241</p><p>Analysis of Appropriateness of Model241</p><p>Analysis of Variance243</p><p>Estimation of Regression Parameters245</p><p>Estimation of Mean Response245</p><p>Prediction Limits for New Observations247</p><p>Cited Reference248</p><p>Problems248</p><p>Exercises253</p><p>Projects254</p><p>Chapter 7 Multiple Regression Ⅱ256</p><p>7.1 Extra Sums of Squares256</p><p>Basic Ideas256</p><p>Definitions259</p><p>Decomposition of SSR into Extra Sums of Squares260</p><p>ANOVA Table Containing Decomposition of SSR261</p><p>7.2 Uses of Extra Sums of Squares in Tests for Regression Coefficients263</p><p>Test whether a Single βk=0263</p><p>Test whether Several βk=0264</p><p>7.3 Summary of Tests Concerning Regression Coefficients266</p><p>Test whether All βk=0266</p><p>Test whether a Single βk=0267</p><p>Test whether Some βk=0267</p><p>Other Tests268</p><p>7.4 Coefficients of Partial Determination268</p><p>Two Predictor Variables269</p><p>General Case269</p><p>Coefficients of Partial Correlation270</p><p>7.5 Standardized Multiple Regression Model271</p><p>Roundoff Errors in Normal Equations Calculations271</p><p>Lack of Comparability in Regression Coefficients272</p><p>Correlation Transformation272</p><p>Standardized Regression Model273</p><p>X'X Matrix for Transformed Variables274</p><p>Estimated Standardized Regression Coefficients275</p><p>7.6 Multicollinearity and Its Effects278</p><p>Uncorrelated Predictor Variables279</p><p>Nature of Problem when Predictor Variables Are Perfectly Correlated281</p><p>Effects of Multicollinearity283</p><p>Need for More Powerful Diagnostics for Multicollinearity289</p><p>Cited Reference289</p><p>Problems289</p><p>Exercise292</p><p>Projects293</p><p>Chapter 8 Regression Models for Quantitative and Qualitative Predictors294</p><p>8.1 Polynomial Regression Models294</p><p>Uses of Polynomial Models294</p><p>One Predictor Variable—Second Order295</p><p>One Predictor Variable—Third Order296</p><p>One Predictor Variable—Higher Orders296</p><p>Two Predictor Variables—Second Order297</p><p>Three Predictor Variables—Second Order298</p><p>Implementation of Polynomial Regression Models298</p><p>Case Example300</p><p>Some Further Comments on Polynomial Regression305</p><p>8.2 Interaction Regression Models306</p><p>Interaction Effects306</p><p>Interpretation of Interaction Regression Models with Linear Effects306</p><p>Interpretation of Interaction Regression Models with Curvilinear Effects309</p><p>Implementation of Interaction Regression Models311</p><p>8.3 Qualitative Predictors313</p><p>Qualitative Predictor with Two Classes314</p><p>Interpretation of Regression Coefficients315</p><p>Qualitative Predictor with More than Two Classes318</p><p>Time Series Applications319</p><p>8.4 Some Considerations in Using Indicator Variables321</p><p>Indicator Variables versus Allocated Codes321</p><p>Indicator Variables versus Quantitative Variables322</p><p>Other Codings for Indicator Variables323</p><p>8.5 Modeling Interactions between Quantitative and Qualitative Predictors324</p><p>Meaning of Regression Coefficients324</p><p>8.6 More Complex Models327</p><p>More than One Qualitative Predictor Variable328</p><p>Qualitative Predictor Variables Only329</p><p>8.7 Comparison of Two or More Regression Functions329</p><p>Soap Production Lines Example330</p><p>Instrument Calibration Study Example334</p><p>Cited Reference335</p><p>Problems335</p><p>Exercises340</p><p>Projects341</p><p>Case Study342</p><p>Chapter 9 Building the Regression Model Ⅰ:Model Selection and Validation343</p><p>9.1 Overview of Model-Building Process343</p><p>Data Collection343</p><p>Data Preparation346</p><p>Preliminary Model Investigation346</p><p>Reduction of Explanatory Variables347</p><p>Model Refinement and Selection349</p><p>Model Validation350</p><p>9.2 Surgical Unit Example350</p><p>9.3 Criteria for Model Selection353</p><p>R2 p or SSEp Criterion354</p><p>R2 a,p or MSEp Criterion355</p><p>Mallows' Cp Criterion357</p><p>A1Cp and SBCp Criteria359</p><p>PRESSp Criterion360</p><p>9.4 Automatic Search Procedures for Model Selection361</p><p>&quot;Best&quot; Subsets Algorithm361</p><p>Stepwise Regression Methods364</p><p>Forward Stepwise Regression364</p><p>Other Stepwise Procedures367</p><p>9.5 Some Final Comments on Automatic Model Selection Procedures368</p><p>9.6 Model Validation369</p><p>Collection of New Data to Check Model370</p><p>Comparison with Theory, Empirical Evidence,or Simulation Results371</p><p>Data Splitting372</p><p>Cited References375</p><p>Problems376</p><p>Exercise380</p><p>Projects381</p><p>Case Studies382</p><p>Chapter 10 Building the Regression Model Ⅱ:Diagnostics384</p><p>10.1 Model Adequacy for a Predictor Variable—Added-Variable Plots384</p><p>10.2 Identifying Outlying Y Observations—Studentized Deleted Residuals390</p><p>Outlying Cases390</p><p>Residuals and Semistudentized Residuals392</p><p>Hat Matrix392</p><p>Studentized Residuals394</p><p>Deleted Residuals395</p><p>Studentized Deleted Residuals396</p><p>10.3 Identifying Outlying X Observations—Hat Matrix Leverage Values398</p><p>Use of Hat Matrix for Identifying Outlying X Observations398</p><p>Use of Hat Matrix to Identify Hidden Extrapolation400</p><p>10.4 Identifying Influential Cases—DFFITS,Cook's Distance,and DFBETAS Measures400</p><p>Influence on Single Fitted Value DFFITS401</p><p>Influence on All Fitted Values—Cook's Distance402</p><p>Influence on the Regression Coefficients DFBETAS404</p><p>Influence on Inferences405</p><p>Some Final Comments406</p><p>10.5 Multicollinearity Diagnostics—Variance Inflation Factor406</p><p>Informal Diagnostics407</p><p>Variance Inflation Factor408</p><p>10.6 Surgical Unit Example Continued410</p><p>Cited References414</p><p>Problems414</p><p>Exercises419</p><p>Projects419</p><p>Case Studies420</p><p>Chapter 11 Building the Regression Model Ⅲ:Remedial Measures421</p><p>11.1 Unequal Error Variances Remedial Measures—Weighted Least Squares421</p><p>Error Variances Known422</p><p>Error Variances Known up to Proportionality Constant424</p><p>Error Variances Unknown424</p><p>11.2 Multicollinearity Remedial Measures—Ridge Regression431</p><p>Some Remedial Measures431</p><p>Ridge Regression432</p><p>11.3 Remedial Measures for Influential Cases—Robust Regression437</p><p>Robust Regression438</p><p>IRLS Robust Regression439</p><p>11.4 Nonparametric Regression:Lowess Method and Regression Trees449</p><p>Lowess Method449</p><p>Regression Trees453</p><p>11.5 Remedial Measures for Evaluating Precision in Nonstandard Situations—Bootstrapping458</p><p>General Procedure459</p><p>Bootstrap Sampling459</p><p>Bootstrap Confidence Intervals460</p><p>11.6 Case Example—MNDOT Traffic Estimation464</p><p>The AADT Database464</p><p>Model Development465</p><p>Weighted Least Squares Estimation468</p><p>Cited References471</p><p>Problems472</p><p>Exercises476</p><p>Projects476</p><p>Case Studies480</p><p>Chapter 12 Autocorrelation in Time Series Data481</p><p>12.1 Problems of Autocorrelation481</p><p>12.2 First-Order Autoregressive Error Model484</p><p>Simple Linear Regression484</p><p>Multiple Regression484</p><p>Properties of Error Terms485</p><p>12.3 Durbin-Watson Test for Autocorrelation487</p><p>12.4 Remedial Measures for Autocorrelation490</p><p>Addition of Predictor Variables490</p><p>Use of Transformed Variables490</p><p>Cochrane-Orcutt Procedure492</p><p>Hildreth-Lu Procedure495</p><p>First Differences Procedure496</p><p>Comparison of Three Methods498</p><p>12.5 Forecasting with Autocorrelated Error Terms499</p><p>Cited References502</p><p>Problems502</p><p>Exercises507</p><p>Projects508</p><p>Case Studies508</p><p>PART THREE NONLINEAR REGRESSION509</p><p>Chapter 13 Introduction to Nonlinear Regression and Neural Networks510</p><p>13.1 Linear and Nonlinear Regression Models510</p><p>Linear Regression Models510</p><p>Nonlinear Regression Models511</p><p>Estimation of Regression Parameters514</p><p>13.2 Least Squares Estimation in Nonlinear Regression515</p><p>Solution of Normal Equations517</p><p>Direct Numerical Search—Gauss-Newton Method518</p><p>Other Direct Search Procedures525</p><p>13.3 Model Building and Diagnostics526</p><p>13.4 Inferences about Nonlinear Regression Parameters527</p><p>Estimate of Error Term Variance527</p><p>Large-Sample Theory528</p><p>When Is Large-Sample Theory Applicable?528</p><p>Interval Estimation of a Single γk531</p><p>Simultaneous Interval Estimation of Several γk532</p><p>Test Concerning a Single γk532</p><p>Test Concerning Several γk533</p><p>13.5 Learning Curve Example533</p><p>13.6 Introduction to Neural Network Modeling537</p><p>Neural Network Model537</p><p>Network Representation540</p><p>Neural Network as Generalization of Linear Regression541</p><p>Parameter Estimation:Penalized Least Squares542</p><p>Example:Ischemic Heart Disease543</p><p>Model Interpretation and Prediction546</p><p>Some Final Comments on Neural Network Modeling547</p><p>Cited References547</p><p>Problems548</p><p>Exercises552</p><p>Projects552</p><p>Case Studies554</p><p>Chapter 14 Logistic Regression,Poisson Regression,and Generalized Linear Models555</p><p>14.1 Regression Models with Binary Response Variable555</p><p>Meaning of Response Function when Outcome Variable Is Binary556</p><p>Special Problems when Response Variable Is Binary557</p><p>14.2 Sigmoidal Response Functions for Binary Responses559</p><p>Probit Mean Response Function559</p><p>Logistic Mean Response Function560</p><p>Complementary Log-Log Response Function562</p><p>14.3 Simple Logistic Regression563</p><p>Simple Logistic Regression Model563</p><p>Likelihood Function564</p><p>Maximum Likelihood Estimation564</p><p>Interpretation of b1567</p><p>Use of Probit and Complementary Log-Log Response Functions568</p><p>Repeat Observations—Binomial Outcomes568</p><p>14.4 Multiple Logistic Regression570</p><p>Multiple Logistic Regression Model570</p><p>Fitting of Model571</p><p>Polynomial Logistic Regression575</p><p>14.5 Inferences about Regression Parameters577</p><p>Test Concerning a Single βk:Wald Test578</p><p>Interval Estimation of a Single βk579</p><p>Test whether Several βk=0:Likelihood Ratio Test580</p><p>14.6 Automatic Model Selection Methods582</p><p>Model Selection Criteria582</p><p>Best Subsets Procedures583</p><p>Stepwise Model Selection583</p><p>14.7 Tests for Goodness of Fit586</p><p>Pearson Chi-Square Goodness of Fit Test586</p><p>Deviance Goodness of Fit Test588</p><p>Hosmer-Lemeshow Goodness of Fit Test589</p><p>14.8 Logistic Regression Diagnostics591</p><p>Logistic Regression Residuals591</p><p>Diagnostic Residual Plots594</p><p>Detection of Influential Observations598</p><p>14.9 Inferences about Mean Response602</p><p>Point Estimator602</p><p>Interval Estimation602</p><p>Simultaneous Confidence Intervals for Several Mean Responses603</p><p>14.10 Prediction of a New Observation604</p><p>Choice of Prediction Rule604</p><p>Validation of Prediction Error Rate607</p><p>14.11 Polytomous Logistic Regression for Nominal Response608</p><p>Pregnancy Duration Data with Polytomous Response609</p><p>J—1 Baseline-Category Logitsfor Nominal Response610</p><p>Maximum Likelihood Estimation612</p><p>14.12 Polytomous Logistic Regression for Ordinal Response614</p><p>14.13 Poisson Regression618</p><p>Poisson Distribution618</p><p>Poisson Regression Model619</p><p>Maximum Likelihood Estimation620</p><p>Model Development620</p><p>Inferences621</p><p>14.14 Generalized Linear Models623</p><p>Cited References624</p><p>Problems625</p><p>Exercises634</p><p>Projects635</p><p>Case Studies640</p><p>Appendix A Some Basic Results in Probability and Statistics641</p><p>Appendix B Tables659</p><p>Appendix C Data Sets677</p><p>Appendix D Selected Bibliography687</p><p>Index695</p><p></p></div></div><div class="d-rt"><h3>热门推荐</h3><ul><li><a href="/book/2844360.html">2844360.html</a></li><li><a href="/book/991333.html">991333.html</a></li><li><a href="/book/2841532.html">2841532.html</a></li><li><a href="/book/3273834.html">3273834.html</a></li><li><a href="/book/932371.html">932371.html</a></li><li><a href="/book/1341101.html">1341101.html</a></li><li><a href="/book/2513243.html">2513243.html</a></li><li><a href="/book/1723391.html">1723391.html</a></li><li><a href="/book/1285731.html">1285731.html</a></li><li><a href="/book/2466885.html">2466885.html</a></li></ul></div></div><div id="footer"><p>Copyright&nbsp;&copy;&nbsp;2025&nbsp;&nbsp;<a href="/list/">最新更新</a></p><p>请使用FDM BitComet qBittorrent uTorrent等BT下载工具，下载本站电子书资源！首推Free Download Manager下载软件。文件页数>标注页数[分册图书除外]</p></div></body></html>