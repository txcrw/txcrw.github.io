<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><script type="text/javascript" src="https://file.bkxsj.com/skin/book/js/sk.js"></script><meta name="robots" content="index,follow"><title>统计机器学习导论[PDF|Epub|txt|kindle电子书版本网盘下载]-灵感之桥</title><meta name="Keywords" content="统计机器学习导论"/><meta name="description" content="统计机器学习导论pdf下载文件大小为35MB,PDF页数为351页"/><meta http-equiv="X-UA-Compatible" content="IE=9; IE=8; IE=7; IE=EDGE;chrome=1"><link type="image/x-icon" rel="shortcut icon" href="https://www.shukui.net/skin/book/images/favicon.ico"><link type="text/css" rel="stylesheet" href="https://www.shukui.net/skin/book/css/style.css"><style>#main .d-main {margin-left: 0;width: 620px;}.down-btn {animation: myShake 2.5s linear .15s infinite}@keyframes myShake {0%, 66% {transform: translateZ(0)}67%, 73.6%, 83.6%, 93.6%, to {animation-timing-function: cubic-bezier(.215, .61, .355, 1);transform: translateZ(0)}80.3%, 81.4% {animation-timing-function: cubic-bezier(.755, .05, .855, .06);transform: translate3d(0, -4px, 0)}90.3% {animation-timing-function: cubic-bezier(.755, .05, .855, .06);transform: translate3d(0, -2px, 0)}97% {transform: translate3d(0, -.5px, 0)}}.copylink-btn {margin-right: 20px;}.copymd5-btn {margin-bottom: 25px;margin-left: 10px;}</style></head><body><div id="header"><div class="inner"><div class="logo"><a href="/"><img width="103" height="25" alt="灵感之桥"src="https://www.shukui.net/skin/book/images/logo.png"></a></div><div class="search"><form action="/so/search.php" target="_blank"><input type="text" autocomplete="off" id="bdcsMain" name="q" placeholder="书名 / 作者 / 出版社 / ISBN"class="inp-txt"><select class="inp-select" id="datasource" onchange="selectDatasource(this)"><option value="so">主库</option><option value="s">从库</option></select><input type="submit" value="搜索" class="inp-btn"></form></div></div></div><div id="main"><div class="d-main"><div class="tit"><h3>图书介绍</h3></div><h1 class="book-name">统计机器学习导论PDF|Epub|txt|kindle电子书版本网盘下载</h1><div class="d-info"><div class="b-thumb"><img src="https://www.shukui.net/cover/5/31352126.jpg" alt="统计机器学习导论"></div><div class="b-info"><ul><li>（日）杉山将（MASASHISUGIYAMA）著；谢宁，李柏杨，肖竹，罗宇轩等译 著</li><li>出版社： 北京：机械工业出版社</li><li>ISBN：9787111596790</li><li>出版时间：2018</li><li>标注页数：338页</li><li>文件大小：35MB</li><li>文件页数：351页</li><li>主题词：机器学习</li></ul></div></div><div class="tit"><h3>PDF下载</h3></div><div></br><a style="color:red;" rel="external nofollow" href="https://www.kjlm.net/ebook/1223250.html"target="_blank"><b>点此进入-本书在线PDF格式电子书下载【推荐-云解压-方便快捷】直接下载PDF格式图书。移动端-PC端通用</a></b></br><a class="down-btn" rel="external nofollow" href="https://down.trackerbk.com/bt/03/31352126.torrent"target="_blank">种子下载</a>[BT下载速度快]温馨提示：（请使用BT下载软件FDM进行下载）<a rel="nofollow" href="https://www.freedownloadmanager.org/zh/" target="_blank">软件下载地址页</a><a class="down-btn" rel="external nofollow" href="https://down.p2spdb.com/03/31352126.rar" target="_blank">直链下载</a>[便捷但速度慢]&nbsp;&nbsp;<a style="color:red;" rel="external nofollow" href="https://pdfyl.ertongbook.com/28/31352126.pdf" target="_blank"><b>[在线试读本书]</b></a>&nbsp;&nbsp;<b> <a style="color:red;" rel="external nofollow" href="https://web.jyjl.org/index/recovery.html" target="_blank">[在线获取解压码]</a></b><div class="copymd5-btn"><a href="javascript:copyToClip('aa16bd2e9d1864b5caae367825adfa8b')">点击复制MD5值：aa16bd2e9d1864b5caae367825adfa8b</a></div></div><div class="tit"><h3>下载说明</h3></div><div style="margin:20px 10px"><h2>统计机器学习导论PDF格式电子书版下载</h2>下载的文件为RAR压缩包。需要使用解压软件进行解压得到PDF格式图书。<br><br><div class="copymd5-btn"><a href="javascript:copyToClip('magnet:?xt=urn:btih:RX6G6JQ2LJW7PBBEDNUSCQM7ICDMHIWK')">点击复制85GB完整离线版磁力链接到迅雷FDM等BT下载工具进行下载</a>&nbsp;&nbsp;<a rel="nofollow" target="_blank">详情点击-查看共享计划</a></div>建议使用BT下载工具Free Download Manager进行下载,简称FDM(免费,没有广告,支持多平台）。本站资源全部打包为BT种子。所以需要使用专业的BT下载软件进行下载。如BitComet qBittorrent uTorrent等BT下载工具。迅雷目前由于本站不是热门资源。不推荐使用！后期资源热门了。安装了迅雷也可以迅雷进行下载！<br><br><b>（文件页数 要大于 标注页数，上中下等多册电子书除外）</b><br><br><p style="color:red;"> <b>注意：本站所有压缩包均有解压码：</b> <a rel="nofollow" target="_blank"><b>点击下载压缩包解压工具</b></a></p></div><div class="tit"><h3>图书目录</h3></div><div id="book-contents"><p>第一部分 绪论2</p><p>第1章 统计机器学习2</p><p>1.1学习的类型2</p><p>1.2机器学习任务举例3</p><p>1.2.1监督学习3</p><p>1.2.2非监督学习4</p><p>1.2.3进一步的主题4</p><p>1.3本书结构5</p><p>第二部分 概率与统计8</p><p>第2章 随机变量与概率分布8</p><p>2.1数学基础8</p><p>2.2概率9</p><p>2.3随机变量和概率分布10</p><p>2.4概率分布的性质11</p><p>2.4.1期望、中位数和众数11</p><p>2.4.2方差和标准差13</p><p>2.4.3偏度、峰度和矩13</p><p>2.5随便变量的变换15</p><p>第3章 离散概率分布的实例17</p><p>3.1离散均匀分布17</p><p>3.2二项分布17</p><p>3.3超几何分布18</p><p>3.4泊松分布21</p><p>3.5负二项分布23</p><p>3.6几何分布24</p><p>第4章 连续概率分布的实例25</p><p>4.1连续均匀分布25</p><p>4.2正态分布25</p><p>4.3伽马分布、指数分布和卡方分布27</p><p>4.4Beta分布29</p><p>4.5柯西分布和拉普拉斯分布31</p><p>4.6t分布和F分布33</p><p>第5章 多维概率分布35</p><p>5.1联合概率分布35</p><p>5.2条件概率分布36</p><p>5.3列联表36</p><p>5.4贝叶斯定理36</p><p>5.5协方差与相关性38</p><p>5.6独立性39</p><p>第6章 多维概率分布的实例42</p><p>6.1多项分布42</p><p>6.2多元正态分布43</p><p>6.3狄利克雷分布45</p><p>6.4威沙特分布48</p><p>第7章 独立随机变量之和50</p><p>7.1卷积50</p><p>7.2再生性50</p><p>7.3大数定律51</p><p>7.4中心极限定理53</p><p>第8章 概率不等式55</p><p>8.1联合界55</p><p>8.2概率不等式55</p><p>8.2.1马尔可夫不等式和切尔诺夫不等式55</p><p>8.2.2坎泰利不等式和切比雪夫不等式56</p><p>8.3期望不等式57</p><p>8.3.1琴生不等式57</p><p>8.3.2赫尔德不等式和施瓦茨不等式57</p><p>8.3.3闵可夫斯基不等式58</p><p>8.3.4康托洛维奇不等式58</p><p>8.4独立随机变量和的不等式59</p><p>8.4.1切比雪夫不等式和切尔诺夫不等式59</p><p>8.4.2霍夫丁不等式和伯恩斯坦不等式59</p><p>8.4.3贝内特不等式60</p><p>第9章 统计估计62</p><p>9.1统计估计基础62</p><p>9.2点估计62</p><p>9.2.1参数密度估计62</p><p>9.2.2非参数密度估计63</p><p>9.2.3回归和分类64</p><p>9.2.4模型选择64</p><p>9.3区间估计65</p><p>9.3.1基于正态样本期望的区间估计65</p><p>9.3.2bootstrap置信区间65</p><p>9.3.3贝叶斯置信区间66</p><p>第10章 假设检验67</p><p>10.1假设检验基础67</p><p>10.2正态样本期望的检验68</p><p>10.3尼曼-皮尔森引理68</p><p>10.4列联表检验69</p><p>10.5正态样本期望差值检验70</p><p>10.5.1无对应关系的两组样本70</p><p>10.5.2有对应关系的两组样本71</p><p>10.6秩的无参检验72</p><p>10.6.1无对应关系的两组样本72</p><p>10.6.2有对应关系的两组样本73</p><p>10.7蒙特卡罗检验74</p><p>第三部分 统计模式识别的生成式方法76</p><p>第11章 通过生成模型估计的模式识别76</p><p>11.1模式识别的公式化76</p><p>11.2统计模式识别77</p><p>11.3分类器训练的准则79</p><p>11.3.1最大后验概率规则79</p><p>11.3.2最小错误分类率准则79</p><p>11.3.3贝叶斯决策规则80</p><p>11.3.4讨论81</p><p>11.4生成式方法和判别式方法81</p><p>第12章 极大似然估计83</p><p>12.1定义83</p><p>12.2高斯模型84</p><p>12.3类-后验概率的计算86</p><p>12.4Fisher线性判别分析88</p><p>12.5手写数字识别90</p><p>12.5.1预备知识90</p><p>12.5.2线性判别分析的实现90</p><p>12.5.3多分类器方法91</p><p>第13章 极大似然估计的性质93</p><p>13.1一致性93</p><p>13.2渐近无偏性93</p><p>13.3渐近有效性94</p><p>13.3.1一维的情况94</p><p>13.3.2多维的情况94</p><p>13.4渐近正态性95</p><p>13.5总结97</p><p>第14章 极大似然估计的模型选择98</p><p>14.1模型选择98</p><p>14.2KL散度99</p><p>14.3AIC信息论准则100</p><p>14.4交叉检验102</p><p>14.5讨论103</p><p>第15章 高斯混合模型的极大似然估计104</p><p>15.1高斯混合模型104</p><p>15.2极大似然估计105</p><p>15.3梯度上升算法107</p><p>15.4EM算法108</p><p>第16章 非参数估计112</p><p>16.1直方图方法112</p><p>16.2问题描述113</p><p>16.3核密度估计115</p><p>16.3.1Parzen窗法115</p><p>16.3.2利用核的平滑116</p><p>16.3.3带宽的选择117</p><p>16.4最近邻密度估计118</p><p>16.4.1最近邻距离118</p><p>16.4.2最近邻分类器118</p><p>第17章 贝叶斯推理123</p><p>17.1贝叶斯预测分布123</p><p>17.1.1定义123</p><p>17.1.2与极大似然估计的比较124</p><p>17.1.3计算问题124</p><p>17.2共轭先验125</p><p>17.3最大后验估计126</p><p>17.4贝叶斯模型选择128</p><p>第18章 边缘相似的解析近似131</p><p>18.1拉普拉斯近似131</p><p>18.1.1高斯密度估计131</p><p>18.1.2例证132</p><p>18.1.3应用于边际似然逼近133</p><p>18.1.4贝叶斯信息准则133</p><p>18.2变分近似134</p><p>18.2.1变分贝叶斯最大期望算法134</p><p>18.2.2与一般最大期望法的关系135</p><p>第19章 预测分布的数值近似137</p><p>19.1蒙特卡罗积分137</p><p>19.2重要性采样138</p><p>19.3采样算法139</p><p>19.3.1逆变换采样139</p><p>19.3.2拒绝采样141</p><p>19.3.3马尔可夫链蒙特卡罗方法142</p><p>第20章 贝叶斯混合模型147</p><p>20.1高斯混合模型147</p><p>20.1.1贝叶斯公式化147</p><p>20.1.2变分推断148</p><p>20.1.3吉布斯采样151</p><p>20.2隐狄利克雷分配模型154</p><p>20.2.1主题模型154</p><p>20.2.2贝叶斯公式化154</p><p>20.2.3吉布斯采样155</p><p>第四部分 统计机器学习的判别式方法158</p><p>第21章 学习模型158</p><p>21.1线性参数模型158</p><p>21.2核模型159</p><p>21.3层次模型161</p><p>第22章 最小二乘回归163</p><p>22.1最小二乘法163</p><p>22.2线性参数模型的解决方案163</p><p>22.3最小二乘法的特性166</p><p>22.4大规模数据的学习算法167</p><p>22.5层次模型的学习算法168</p><p>第23章 具有约束的最小二乘回归171</p><p>23.1子空间约束的最小二乘171</p><p>23.2l2约束的最小二乘172</p><p>23.3模型选择175</p><p>第24章 稀疏回归178</p><p>24.1l1约束的最小二乘178</p><p>24.2解决l1约束的最小二乘179</p><p>24.3稀疏学习的特征选择181</p><p>24.4若干扩展181</p><p>24.4.1广义l1约束最小二乘182</p><p>24.4.2lp约束最小二乘182</p><p>24.4.3l1＋l2约束最小二乘183</p><p>24.4.4l1，2约束最小二乘184</p><p>24.4.5迹范数约束最小二乘184</p><p>第25章 稳健回归186</p><p>25.1l2损失最小化的非稳健性186</p><p>25.2l1损失最小化187</p><p>25.3Huber损失最小化187</p><p>25.3.1定义188</p><p>25.3.2随机梯度算法188</p><p>25.3.3迭代加权最小二乘188</p><p>25.3.4l1约束Huber损失最小化190</p><p>25.4Tukey损失最小化193</p><p>第26章 最小二乘分类器195</p><p>26.1基于最小二乘回归的分类器195</p><p>26.2 0/1损失和间隔196</p><p>26.3多类分类器198</p><p>第27章 支持向量分类200</p><p>27.1最大间隔分类200</p><p>27.1.1硬间隔支持向量分类200</p><p>27.1.2软间隔支持向量分类201</p><p>27.2支持向量分类的对偶最优化问题201</p><p>27.3对偶解的稀疏性203</p><p>27.4使用核技巧的非线性模型204</p><p>27.5多类扩展206</p><p>27.6损失最小化观点207</p><p>27.6.1Hinge损失最小化207</p><p>27.6.2平方Hinge损失最小化208</p><p>27.6.3Ramp损失最小化210</p><p>第28章 概率分类法212</p><p>28.1Logistic回归212</p><p>28.1.1Logistic模型与极大似然估计212</p><p>28.1.2损失最小化的观点214</p><p>28.2最小二乘概率分类214</p><p>第29章 结构化分类217</p><p>29.1序列分类器217</p><p>29.2序列的概率分类217</p><p>29.2.1条件随机场218</p><p>29.2.2极大似然估计219</p><p>29.2.3递归计算219</p><p>29.2.4新样本预测221</p><p>29.3序列的确定性分类222</p><p>第五部分 高级主题226</p><p>第30章 集成学习226</p><p>30.1决策树桩分类器226</p><p>30.2bagging算法227</p><p>30.3boosting算法228</p><p>30.3.1adaboost算法228</p><p>30.3.2损失最小化观点230</p><p>30.4泛化集成学习233</p><p>第31章 在线学习234</p><p>31.1随机梯度下降法234</p><p>31.2被动攻击学习235</p><p>31.2.1分类235</p><p>31.2.2回归237</p><p>31.3加权向量的自适应正则化238</p><p>31.3.1参数的不确定性238</p><p>31.3.2分类239</p><p>31.3.3回归240</p><p>第32章 预测的置信度241</p><p>32.1l2正则化最小二乘的预测方差241</p><p>32.2bootstrap法置信区间估计243</p><p>32.3应用244</p><p>32.3.1时间序列预测244</p><p>32.3.2调整参数的优化245</p><p>第33章 半监督学习248</p><p>33.1流形正则化248</p><p>33.1.1输入样本的流形结构248</p><p>33.1.2计算解决方案249</p><p>33.2协变量移位的适应251</p><p>33.2.1重要度加权学习251</p><p>33.2.2相对重要度加权学习252</p><p>33.2.3重要度加权交叉检验253</p><p>33.2.4重要度估计253</p><p>33.3类别平衡变化下的适应255</p><p>33.3.1类别平衡加权学习256</p><p>33.3.2类别平衡估计256</p><p>第34章 多任务学习259</p><p>34.1任务相似度正则化259</p><p>34.1.1公式化259</p><p>34.1.2解析解260</p><p>34.1.3多任务的有效计算方法260</p><p>34.2多维函数学习261</p><p>34.2.1公式化261</p><p>34.2.2有效的分析解决方案263</p><p>34.3矩阵正则化263</p><p>34.3.1参数矩阵正则化264</p><p>34.3.2迹范数正则化的梯度法265</p><p>第35章 线性降维268</p><p>35.1维度灾难268</p><p>35.2无监督降维法269</p><p>35.2.1主成分分析270</p><p>35.2.2局部保留投影271</p><p>35.3分类的线性判别分析272</p><p>35.3.1Fisher判别分析法273</p><p>35.3.2局部Fisher判别分析法274</p><p>35.3.3半监督局部Fisher判别分析法276</p><p>35.4回归问题的充分降维277</p><p>35.4.1信息论公式化278</p><p>35.4.2直接导数估计279</p><p>35.5矩阵插补282</p><p>第36章 非线性降维285</p><p>36.1利用核技巧的降维285</p><p>36.1.1核主成分分析285</p><p>36.1.2拉普拉斯特征映射288</p><p>36.2通过神经网络的监督降维法289</p><p>36.3通过自编码器的非监督降维法290</p><p>36.3.1自编码器290</p><p>36.3.2通过梯度下降法的训练290</p><p>36.3.3稀疏自编码器292</p><p>36.4通过受限玻尔兹曼机的非监督降维法292</p><p>36.4.1模型293</p><p>36.4.2通过梯度下降法的训练293</p><p>36.5深度学习296</p><p>第37章 聚类297</p><p>37.1k均值聚类297</p><p>37.2核k均值聚类299</p><p>37.3谱聚类299</p><p>37.4调谐参数的选择299</p><p>第38章 异常检测304</p><p>38.1密度估计和局部异常因子304</p><p>38.2支持向量数据描述305</p><p>38.3基于正常值的异常检测308</p><p>第39章 变化检测312</p><p>39.1基于分布模型的变化检测312</p><p>39.1.1KL散度312</p><p>39.1.2Pearson散度313</p><p>39.1.3L2距离313</p><p>39.1.4L1距离315</p><p>39.1.5最大均值差异317</p><p>39.1.6能量距离317</p><p>39.1.7时序变化检测的应用317</p><p>39.2基于结构模型的变化检测318</p><p>39.2.1稀疏极大似然估计319</p><p>39.2.2稀疏密度比估计321</p><p>参考文献324</p><p>索引329</p><p></p></div></div><div class="d-rt"><h3>热门推荐</h3><ul><li><a href="/book/3510047.html">3510047.html</a></li><li><a href="/book/804683.html">804683.html</a></li><li><a href="/book/2710874.html">2710874.html</a></li><li><a href="/book/240643.html">240643.html</a></li><li><a href="/book/1855143.html">1855143.html</a></li><li><a href="/book/1581149.html">1581149.html</a></li><li><a href="/book/1370191.html">1370191.html</a></li><li><a href="/book/3117136.html">3117136.html</a></li><li><a href="/book/1227887.html">1227887.html</a></li><li><a href="/book/2438614.html">2438614.html</a></li></ul></div></div><div id="footer"><p>Copyright&nbsp;&copy;&nbsp;2025&nbsp;&nbsp;<a href="/list/">最新更新</a></p><p>请使用FDM BitComet qBittorrent uTorrent等BT下载工具，下载本站电子书资源！首推Free Download Manager下载软件。文件页数>标注页数[分册图书除外]</p></div></body></html>