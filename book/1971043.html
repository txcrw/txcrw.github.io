<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><script type="text/javascript" src="https://file.bkxsj.com/skin/book/js/sk.js"></script><meta name="robots" content="index,follow"><title>动手学深度学习[PDF|Epub|txt|kindle电子书版本网盘下载]-灵感之桥</title><meta name="Keywords" content="动手学深度学习"/><meta name="description" content="动手学深度学习pdf下载文件大小为201MB,PDF页数为449页"/><meta http-equiv="X-UA-Compatible" content="IE=9; IE=8; IE=7; IE=EDGE;chrome=1"><link type="image/x-icon" rel="shortcut icon" href="https://www.shukui.net/skin/book/images/favicon.ico"><link type="text/css" rel="stylesheet" href="https://www.shukui.net/skin/book/css/style.css"><style>#main .d-main {margin-left: 0;width: 620px;}.down-btn {animation: myShake 2.5s linear .15s infinite}@keyframes myShake {0%, 66% {transform: translateZ(0)}67%, 73.6%, 83.6%, 93.6%, to {animation-timing-function: cubic-bezier(.215, .61, .355, 1);transform: translateZ(0)}80.3%, 81.4% {animation-timing-function: cubic-bezier(.755, .05, .855, .06);transform: translate3d(0, -4px, 0)}90.3% {animation-timing-function: cubic-bezier(.755, .05, .855, .06);transform: translate3d(0, -2px, 0)}97% {transform: translate3d(0, -.5px, 0)}}.copylink-btn {margin-right: 20px;}.copymd5-btn {margin-bottom: 25px;margin-left: 10px;}</style></head><body><div id="header"><div class="inner"><div class="logo"><a href="/"><img width="103" height="25" alt="灵感之桥"src="https://www.shukui.net/skin/book/images/logo.png"></a></div><div class="search"><form action="/so/search.php" target="_blank"><input type="text" autocomplete="off" id="bdcsMain" name="q" placeholder="书名 / 作者 / 出版社 / ISBN"class="inp-txt"><select class="inp-select" id="datasource" onchange="selectDatasource(this)"><option value="so">主库</option><option value="s">从库</option></select><input type="submit" value="搜索" class="inp-btn"></form></div></div></div><div id="main"><div class="d-main"><div class="tit"><h3>图书介绍</h3></div><h1 class="book-name">动手学深度学习PDF|Epub|txt|kindle电子书版本网盘下载</h1><div class="d-info"><div class="b-thumb"><img src="https://www.shukui.net/cover/32/32469776.jpg" alt="动手学深度学习"></div><div class="b-info"><ul><li>杨海玲责任编辑；（美）阿斯顿·张，李沐 著</li><li>出版社： 北京：人民邮电出版社</li><li>ISBN：9787115490841</li><li>出版时间：2019</li><li>标注页数：412页</li><li>文件大小：201MB</li><li>文件页数：449页</li><li>主题词：机器学习</li></ul></div></div><div class="tit"><h3>PDF下载</h3></div><div></br><a style="color:red;" rel="external nofollow" href="https://www.kjlm.net/ebook/1971046.html"target="_blank"><b>点此进入-本书在线PDF格式电子书下载【推荐-云解压-方便快捷】直接下载PDF格式图书。移动端-PC端通用</a></b></br><a class="down-btn" rel="external nofollow" href="https://down.trackerbk.com/bt/06/32469776.torrent"target="_blank">种子下载</a>[BT下载速度快]温馨提示：（请使用BT下载软件FDM进行下载）<a rel="nofollow" href="https://www.freedownloadmanager.org/zh/" target="_blank">软件下载地址页</a><a class="down-btn" rel="external nofollow" href="https://down.p2spdb.com/06/32469776.rar" target="_blank">直链下载</a>[便捷但速度慢]&nbsp;&nbsp;<a style="color:red;" rel="external nofollow" href="https://pdfyl.ertongbook.com/45/32469776.pdf" target="_blank"><b>[在线试读本书]</b></a>&nbsp;&nbsp;<b> <a style="color:red;" rel="external nofollow" href="https://web.jyjl.org/index/recovery.html" target="_blank">[在线获取解压码]</a></b><div class="copymd5-btn"><a href="javascript:copyToClip('7c70ad6345045db918c17859bad42f05')">点击复制MD5值：7c70ad6345045db918c17859bad42f05</a></div></div><div class="tit"><h3>下载说明</h3></div><div style="margin:20px 10px"><h2>动手学深度学习PDF格式电子书版下载</h2>下载的文件为RAR压缩包。需要使用解压软件进行解压得到PDF格式图书。<br><br><div class="copymd5-btn"><a href="javascript:copyToClip('magnet:?xt=urn:btih:RX6G6JQ2LJW7PBBEDNUSCQM7ICDMHIWK')">点击复制85GB完整离线版磁力链接到迅雷FDM等BT下载工具进行下载</a>&nbsp;&nbsp;<a rel="nofollow" target="_blank">详情点击-查看共享计划</a></div>建议使用BT下载工具Free Download Manager进行下载,简称FDM(免费,没有广告,支持多平台）。本站资源全部打包为BT种子。所以需要使用专业的BT下载软件进行下载。如BitComet qBittorrent uTorrent等BT下载工具。迅雷目前由于本站不是热门资源。不推荐使用！后期资源热门了。安装了迅雷也可以迅雷进行下载！<br><br><b>（文件页数 要大于 标注页数，上中下等多册电子书除外）</b><br><br><p style="color:red;"> <b>注意：本站所有压缩包均有解压码：</b> <a rel="nofollow" target="_blank"><b>点击下载压缩包解压工具</b></a></p></div><div class="tit"><h3>图书目录</h3></div><div id="book-contents"><p>第1章 深度学习简介1</p><p>1.1 起源2</p><p>1.2 发展4</p><p>1.3 成功案例6</p><p>1.4 特点7</p><p>小结8</p><p>练习8</p><p>第2章 预备知识9</p><p>2.1 获取和运行本书的代码9</p><p>2.1.1 获取代码并安装运行环境9</p><p>2.1.2 更新代码和运行环境11</p><p>2.1.3 使用GPU版的MXNet11</p><p>小结12</p><p>练习12</p><p>2.2 数据操作12</p><p>2.2.1 创建NDArray12</p><p>2.2.2 运算14</p><p>2.2.3 广播机制16</p><p>2.2.4 索引17</p><p>2.2.5 运算的内存开销17</p><p>2.2.6 NDArray和NumPy相互变换18</p><p>小结19</p><p>练习19</p><p>2.3 自动求梯度19</p><p>2.3.1 简单例子19</p><p>2.3.2 训练模式和预测模式20</p><p>2.3.3 对Python控制流求梯度20</p><p>小结21</p><p>练习21</p><p>2.4 查阅文档21</p><p>2.4.1 查找模块里的所有函数和类21</p><p>2.4.2 查找特定函数和类的使用22</p><p>2.4.3 在MXNet网站上查阅23</p><p>小结24</p><p>练习24</p><p>第3章 深度学习基础25</p><p>3.1 线性回归25</p><p>3.1.1 线性回归的基本要素25</p><p>3.1.2 线性回归的表示方法28</p><p>小结30</p><p>练习30</p><p>3.2 线性回归的从零开始实现30</p><p>3.2.1 生成数据集30</p><p>3.2.2 读取数据集32</p><p>3.2.3 初始化模型参数32</p><p>3.2.4 定义模型33</p><p>3.2.5 定义损失函数33</p><p>3.2.6 定义优化算法33</p><p>3.2.7 训练模型33</p><p>小结34</p><p>练习34</p><p>3.3 线性回归的简洁实现35</p><p>3.3.1 生成数据集35</p><p>3.3.2 读取数据集35</p><p>3.3.3 定义模型36</p><p>3.3.4 初始化模型参数36</p><p>3.3.5 定义损失函数37</p><p>3.3.6 定义优化算法37</p><p>3.3.7 训练模型37</p><p>小结38</p><p>练习38</p><p>3.4 softmax回归38</p><p>3.4.1 分类问题38</p><p>3.4.2 softmax回归模型39</p><p>3.4.3 单样本分类的矢量计算表达式40</p><p>3.4.4 小批量样本分类的矢量计算表达式40</p><p>3.4.5 交叉熵损失函数41</p><p>3.4.6 模型预测及评价42</p><p>小结42</p><p>练习42</p><p>3.5 图像分类数据集（Fashion-MNIST）42</p><p>3.5.1 获取数据集42</p><p>3.5.2 读取小批量44</p><p>小结45</p><p>练习45</p><p>3.6 softmax回归的从零开始实现45</p><p>3.6.1 读取数据集45</p><p>3.6.2 初始化模型参数45</p><p>3.6.3 实现softmax运算46</p><p>3.6.4 定义模型46</p><p>3.6.5 定义损失函数47</p><p>3.6.6 计算分类准确率47</p><p>3.6.7 训练模型48</p><p>3.6.8 预测48</p><p>小结49</p><p>练习49</p><p>3.7 softmax回归的简洁实现49</p><p>3.7.1 读取数据集49</p><p>3.7.2 定义和初始化模型50</p><p>3.7.3 softmax和交叉熵损失函数50</p><p>3.7.4 定义优化算法50</p><p>3.7.5 训练模型50</p><p>小结50</p><p>练习50</p><p>3.8 多层感知机51</p><p>3.8.1 隐藏层51</p><p>3.8.2 激活函数52</p><p>3.8.3 多层感知机55</p><p>小结55</p><p>练习55</p><p>3.9 多层感知机的从零开始实现56</p><p>3.9.1 读取数据集56</p><p>3.9.2 定义模型参数56</p><p>3.9.3 定义激活函数56</p><p>3.9.4 定义模型56</p><p>3.9.5 定义损失函数57</p><p>3.9.6 训练模型57</p><p>小结57</p><p>练习57</p><p>3.10 多层感知机的简洁实现57</p><p>3.10.1 定义模型58</p><p>3.10.2 训练模型58</p><p>小结58</p><p>练习58</p><p>3.11 模型选择、欠拟合和过拟合58</p><p>3.11.1 训练误差和泛化误差59</p><p>3.11.2 模型选择59</p><p>3.11.3 欠拟合和过拟合60</p><p>3.11.4 多项式函数拟合实验61</p><p>小结65</p><p>练习65</p><p>3.12 权重衰减65</p><p>3.12.1 方法65</p><p>3.12.2 高维线性回归实验66</p><p>3.12.3 从零开始实现66</p><p>3.12.4 简洁实现68</p><p>小结70</p><p>练习70</p><p>3.13 丢弃法70</p><p>3.13.1 方法70</p><p>3.13.2 从零开始实现71</p><p>3.13.3 简洁实现73</p><p>小结74</p><p>练习74</p><p>3.14 正向传播、反向传播和计算图74</p><p>3.14.1 正向传播74</p><p>3.14.2 正向传播的计算图75</p><p>3.14.3 反向传播75</p><p>3.14.4 训练深度学习模型76</p><p>小结77</p><p>练习77</p><p>3.15 数值稳定性和模型初始化77</p><p>3.15.1 衰减和爆炸77</p><p>3.15.2 随机初始化模型参数78</p><p>小结78</p><p>练习79</p><p>3.16 实战Kaggle比赛：房价预测79</p><p>3.16.1 Kaggle比赛79</p><p>3.16.2 读取数据集80</p><p>3.16.3 预处理数据集81</p><p>3.16.4 训练模型82</p><p>3.16.5 k折交叉验证82</p><p>3.16.6 模型选择83</p><p>3.16.7 预测并在Kaggle提交结果84</p><p>小结85</p><p>练习85</p><p>第4章 深度学习计算86</p><p>4.1 模型构造86</p><p>4.1.1 继承Block类来构造模型86</p><p>4.1.2 Sequential类继承自Block类87</p><p>4.1.3 构造复杂的模型88</p><p>小结89</p><p>练习90</p><p>4.2 模型参数的访问、初始化和共享90</p><p>4.2.1 访问模型参数90</p><p>4.2.2 初始化模型参数92</p><p>4.2.3 自定义初始化方法93</p><p>4.2.4 共享模型参数94</p><p>小结94</p><p>练习94</p><p>4.3 模型参数的延后初始化95</p><p>4.3.1 延后初始化95</p><p>4.3.2 避免延后初始化96</p><p>小结96</p><p>练习97</p><p>4.4 自定义层97</p><p>4.4.1 不含模型参数的自定义层97</p><p>4.4.2 含模型参数的自定义层98</p><p>小结99</p><p>练习99</p><p>4.5 读取和存储99</p><p>4.5.1 读写NDArray99</p><p>4.5.2 读写Gluon模型的参数100</p><p>小结101</p><p>练习101</p><p>4.6 GPU计算101</p><p>4.6.1 计算设备102</p><p>4.6.2 NDArray的GPU计算102</p><p>4.6.3 Gluon的GPU计算104</p><p>小结105</p><p>练习105</p><p>第5章 卷积神经网络106</p><p>5.1 二维卷积层106</p><p>5.1.1 二维互相关运算106</p><p>5.1.2 二维卷积层107</p><p>5.1.3 图像中物体边缘检测108</p><p>5.1.4 通过数据学习核数组109</p><p>5.1.5 互相关运算和卷积运算109</p><p>5.1.6 特征图和感受野110</p><p>小结110</p><p>练习110</p><p>5.2 填充和步幅111</p><p>5.2.1 填充111</p><p>5.2.2 步幅112</p><p>小结113</p><p>练习113</p><p>5.3 多输入通道和多输出通道114</p><p>5.3.1 多输入通道114</p><p>5.3.2 多输出通道115</p><p>5.3.3 1×1卷积层116</p><p>小结117</p><p>练习117</p><p>5.4 池化层117</p><p>5.4.1 二维最大池化层和平均池化层117</p><p>5.4.2 填充和步幅119</p><p>5.4.3 多通道120</p><p>小结120</p><p>练习121</p><p>5.5 卷积神经网络（LeNet）121</p><p>5.5.1 LeNet模型121</p><p>5.5.2 训练模型122</p><p>小结124</p><p>练习124</p><p>5.6 深度卷积神经网络（AlexNet）124</p><p>5.6.1 学习特征表示125</p><p>5.6.2 AlexNet126</p><p>5.6.3 读取数据集127</p><p>5.6.4 训练模型128</p><p>小结128</p><p>练习129</p><p>5.7 使用重复元素的网络（VGG）129</p><p>5.7.1 VGG块129</p><p>5.7.2 VGG网络129</p><p>5.7.3 训练模型130</p><p>小结131</p><p>练习131</p><p>5.8 网络中的网络（NiN）131</p><p>5.8.1 NiN块131</p><p>5.8.2 NiN模型132</p><p>5.8.3 训练模型133</p><p>小结134</p><p>练习134</p><p>5.9 含并行连结的网络（GoogLeNet）134</p><p>5.9.1 Inception块134</p><p>5.9.2 GoogLeNet模型135</p><p>5.9.3 训练模型137</p><p>小结137</p><p>练习137</p><p>5.10 批量归一化138</p><p>5.10.1 批量归一化层138</p><p>5.10.2 从零开始实现139</p><p>5.10.3 使用批量归一化层的LeNet140</p><p>5.10.4 简洁实现141</p><p>小结142</p><p>练习142</p><p>5.11 残差网络（ResNet）143</p><p>5.11.1 残差块143</p><p>5.11.2 ResNet模型145</p><p>5.11.3 训练模型146</p><p>小结146</p><p>练习146</p><p>5.12 稠密连接网络（DenseNet）147</p><p>5.12.1 稠密块147</p><p>5.12.2 过渡层148</p><p>5.12.3 DenseNet模型148</p><p>5.12.4 训练模型149</p><p>小结149</p><p>练习149</p><p>第6章 循环神经网络150</p><p>6.1 语言模型150</p><p>6.1.1 语言模型的计算151</p><p>6.1.2 n元语法151</p><p>小结152</p><p>练习152</p><p>6.2 循环神经网络152</p><p>6.2.1 不含隐藏状态的神经网络152</p><p>6.2.2 含隐藏状态的循环神经网络152</p><p>6.2.3 应用：基于字符级循环神经网络的语言模型154</p><p>小结155</p><p>练习155</p><p>6.3 语言模型数据集（歌词）155</p><p>6.3.1 读取数据集155</p><p>6.3.2 建立字符索引156</p><p>6.3.3 时序数据的采样156</p><p>小结158</p><p>练习159</p><p>6.4 循环神经网络的从零开始实现159</p><p>6.4.1 one-hot向量159</p><p>6.4.2 初始化模型参数160</p><p>6.4.3 定义模型160</p><p>6.4.4 定义预测函数161</p><p>6.4.5 裁剪梯度161</p><p>6.4.6 困惑度162</p><p>6.4.7 定义模型训练函数162</p><p>6.4.8 训练模型并创作歌词163</p><p>小结164</p><p>练习164</p><p>6.5 循环神经网络的简洁实现165</p><p>6.5.1 定义模型165</p><p>6.5.2 训练模型166</p><p>小结168</p><p>练习168</p><p>6.6 通过时间反向传播168</p><p>6.6.1 定义模型168</p><p>6.6.2 模型计算图169</p><p>6.6.3 方法169</p><p>小结170</p><p>练习170</p><p>6.7 门控循环单元（GRU）170</p><p>6.7.1 门控循环单元171</p><p>6.7.2 读取数据集173</p><p>6.7.3 从零开始实现173</p><p>6.7.4 简洁实现175</p><p>小结176</p><p>练习176</p><p>6.8 长短期记忆（LSTM）176</p><p>6.8.1 长短期记忆176</p><p>6.8.2 读取数据集179</p><p>6.8.3 从零开始实现179</p><p>6.8.4 简洁实现181</p><p>小结181</p><p>练习182</p><p>6.9 深度循环神经网络182</p><p>小结183</p><p>练习183</p><p>6.10 双向循环神经网络183</p><p>小结184</p><p>练习184</p><p>第7章 优化算法185</p><p>7.1 优化与深度学习185</p><p>7.1.1 优化与深度学习的关系185</p><p>7.1.2 优化在深度学习中的挑战186</p><p>小结188</p><p>练习189</p><p>7.2 梯度下降和随机梯度下降189</p><p>7.2.1 一维梯度下降189</p><p>7.2.2 学习率190</p><p>7.2.3 多维梯度下降191</p><p>7.2.4 随机梯度下降193</p><p>小结194</p><p>练习194</p><p>7.3 小批量随机梯度下降194</p><p>7.3.1 读取数据集195</p><p>7.3.2 从零开始实现196</p><p>7.3.3 简洁实现198</p><p>小结199</p><p>练习199</p><p>7.4 动量法200</p><p>7.4.1 梯度下降的问题200</p><p>7.4.2 动量法201</p><p>7.4.3 从零开始实现203</p><p>7.4.4 简洁实现205</p><p>小结205</p><p>练习205</p><p>7.5 AdaGrad算法206</p><p>7.5.1 算法206</p><p>7.5.2 特点206</p><p>7.5.3 从零开始实现208</p><p>7.5.4 简洁实现209</p><p>小结209</p><p>练习209</p><p>7.6 RMSProp算法209</p><p>7.6.1 算法210</p><p>7.6.2 从零开始实现211</p><p>7.6.3 简洁实现212</p><p>小结212</p><p>练习212</p><p>7.7 AdaDelta算法212</p><p>7.7.1 算法212</p><p>7.7.2 从零开始实现213</p><p>7.7.3 简洁实现214</p><p>小结214</p><p>练习214</p><p>7.8 Adam算法215</p><p>7.8.1 算法215</p><p>7.8.2 从零开始实现216</p><p>7.8.3 简洁实现216</p><p>小结217</p><p>练习217</p><p>第8章 计算性能218</p><p>8.1 命令式和符号式混合编程218</p><p>8.1.1 混合式编程取两者之长220</p><p>8.1.2 使用HybridSequential类构造模型220</p><p>8.1.3 使用HybridBlock类构造模型222</p><p>小结224</p><p>练习224</p><p>8.2 异步计算224</p><p>8.2.1 MXNet中的异步计算224</p><p>8.2.2 用同步函数让前端等待计算结果226</p><p>8.2.3 使用异步计算提升计算性能226</p><p>8.2.4 异步计算对内存的影响227</p><p>小结229</p><p>练习229</p><p>8.3 自动并行计算229</p><p>8.3.1 CPU和GPU的并行计算230</p><p>8.3.2 计算和通信的并行计算231</p><p>小结231</p><p>练习231</p><p>8.4 多GPU计算232</p><p>8.4.1 数据并行232</p><p>8.4.2 定义模型233</p><p>8.4.3 多GPU之间同步数据234</p><p>8.4.4 单个小批量上的多GPU训练236</p><p>8.4.5 定义训练函数236</p><p>8.4.6 多GPU训练实验237</p><p>小结237</p><p>练习237</p><p>8.5 多GPU计算的简洁实现237</p><p>8.5.1 多GPU上初始化模型参数238</p><p>8.5.2 多GPU训练模型239</p><p>小结241</p><p>练习241</p><p>第9章 计算机视觉242</p><p>9.1 图像增广242</p><p>9.1.1 常用的图像增广方法243</p><p>9.1.2 使用图像增广训练模型246</p><p>小结250</p><p>练习250</p><p>9.2 微调250</p><p>热狗识别251</p><p>小结255</p><p>练习255</p><p>9.3 目标检测和边界框255</p><p>边界框256</p><p>小结257</p><p>练习257</p><p>9.4 锚框257</p><p>9.4.1 生成多个锚框257</p><p>9.4.2 交并比259</p><p>9.4.3 标注训练集的锚框260</p><p>9.4.4 输出预测边界框263</p><p>小结265</p><p>练习265</p><p>9.5 多尺度目标检测265</p><p>小结268</p><p>练习268</p><p>9.6 目标检测数据集（皮卡丘）268</p><p>9.6.1 获取数据集269</p><p>9.6.2 读取数据集269</p><p>9.6.3 图示数据270</p><p>小结270</p><p>练习271</p><p>9.7 单发多框检测（SSD）271</p><p>9.7.1 定义模型271</p><p>9.7.2 训练模型275</p><p>9.7.3 预测目标277</p><p>小结278</p><p>练习278</p><p>9.8 区域卷积神经网络（R-CNN）系列280</p><p>9.8.1 R-CNN280</p><p>9.8.2 Fast R-CNN281</p><p>9.8.3 Faster R-CNN283</p><p>9.8.4 Mask R-CNN284</p><p>小结285</p><p>练习285</p><p>9.9 语义分割和数据集285</p><p>9.9.1 图像分割和实例分割285</p><p>9.9.2 Pascal VOC2012语义分割数据集286</p><p>小结290</p><p>练习290</p><p>9.10 全卷积网络（FCN）290</p><p>9.10.1 转置卷积层291</p><p>9.10.2 构造模型292</p><p>9.10.3 初始化转置卷积层294</p><p>9.10.4 读取数据集295</p><p>9.10.5 训练模型296</p><p>9.10.6 预测像素类别296</p><p>小结297</p><p>练习297</p><p>9.11 样式迁移298</p><p>9.11.1 方法298</p><p>9.11.2 读取内容图像和样式图像299</p><p>9.11.3 预处理和后处理图像300</p><p>9.11.4 抽取特征301</p><p>9.11.5 定义损失函数302</p><p>9.11.6 创建和初始化合成图像303</p><p>9.11.7 训练模型304</p><p>小结306</p><p>练习306</p><p>9.12 实战Kaggle比赛：图像分类（CIFAR-10）306</p><p>9.12.1 获取和整理数据集307</p><p>9.12.2 图像增广310</p><p>9.12.3 读取数据集310</p><p>9.12.4 定义模型311</p><p>9.12.5 定义训练函数312</p><p>9.12.6 训练模型312</p><p>9.12.7 对测试集分类并在Kaggle提交结果313</p><p>小结313</p><p>练习313</p><p>9.13 实战Kaggle比赛：狗的品种识别（ImageNet Dogs）314</p><p>9.13.1 获取和整理数据集315</p><p>9.13.2 图像增广316</p><p>9.13.3 读取数据集317</p><p>9.13.4 定义模型318</p><p>9.13.5 定义训练函数318</p><p>9.13.6 训练模型319</p><p>9.13.7 对测试集分类并在Kaggle提交结果319</p><p>小结320</p><p>练习320</p><p>第10章 自然语言处理321</p><p>10.1 词嵌入（word2vec）321</p><p>10.1.1 为何不采用one-hot向量321</p><p>10.1.2 跳字模型322</p><p>10.1.3 连续词袋模型323</p><p>小结325</p><p>练习325</p><p>10.2 近似训练325</p><p>10.2.1 负采样325</p><p>10.2.2 层序softmax326</p><p>小结327</p><p>练习328</p><p>10.3 word2vec的实现328</p><p>10.3.1 预处理数据集328</p><p>10.3.2 负采样331</p><p>10.3.3 读取数据集331</p><p>10.3.4 跳字模型332</p><p>10.3.5 训练模型333</p><p>10.3.6 应用词嵌入模型335</p><p>小结336</p><p>练习336</p><p>10.4 子词嵌入（fastText）336</p><p>小结337</p><p>练习337</p><p>10.5 全局向量的词嵌入（GloVe）337</p><p>10.5.1 GloVe模型338</p><p>10.5.2 从条件概率比值理解GloVe模型339</p><p>小结340</p><p>练习340</p><p>10.6 求近义词和类比词340</p><p>10.6.1 使用预训练的词向量340</p><p>10.6.2 应用预训练词向量341</p><p>小结343</p><p>练习343</p><p>10.7 文本情感分类：使用循环神经网络343</p><p>10.7.1 文本情感分类数据集343</p><p>10.7.2 使用循环神经网络的模型345</p><p>小结347</p><p>练习347</p><p>10.8 文本情感分类：使用卷积神经网络（textCNN）347</p><p>10.8.1 一维卷积层348</p><p>10.8.2 时序最大池化层349</p><p>10.8.3 读取和预处理IMDb数据集350</p><p>10.8.4 textCNN模型350</p><p>小结353</p><p>练习353</p><p>10.9 编码器－解码器（seq2seq）353</p><p>10.9.1 编码器354</p><p>10.9.2 解码器354</p><p>10.9.3 训练模型355</p><p>小结355</p><p>练习355</p><p>10.10 束搜索355</p><p>10.10.1 贪婪搜索356</p><p>10.10.2 穷举搜索357</p><p>10.10.3 束搜索357</p><p>小结358</p><p>练习358</p><p>10.11 注意力机制358</p><p>10.11.1 计算背景变量359</p><p>10.11.2 更新隐藏状态360</p><p>10.11.3 发展361</p><p>小结361</p><p>练习361</p><p>10.12 机器翻译361</p><p>10.12.1 读取和预处理数据集361</p><p>10.12.2 含注意力机制的编码器－解码器363</p><p>10.12.3 训练模型365</p><p>10.12.4 预测不定长的序列367</p><p>10.12.5 评价翻译结果367</p><p>小结369</p><p>练习369</p><p>附录A 数学基础370</p><p>附录B 使用Jupyter记事本376</p><p>附录C 使用AWS运行代码381</p><p>附录D GPU购买指南388</p><p>附录E 如何为本书做贡献391</p><p>附录F d2lzh包索引395</p><p>附录G 中英文术语对照表397</p><p>参考文献402</p><p>索引407</p><p></p></div></div><div class="d-rt"><h3>热门推荐</h3><ul><li><a href="/book/2291552.html">2291552.html</a></li><li><a href="/book/1717931.html">1717931.html</a></li><li><a href="/book/3187632.html">3187632.html</a></li><li><a href="/book/1636134.html">1636134.html</a></li><li><a href="/book/3544422.html">3544422.html</a></li><li><a href="/book/240878.html">240878.html</a></li><li><a href="/book/107104.html">107104.html</a></li><li><a href="/book/1630475.html">1630475.html</a></li><li><a href="/book/2656878.html">2656878.html</a></li><li><a href="/book/3346798.html">3346798.html</a></li></ul></div></div><div id="footer"><p>Copyright&nbsp;&copy;&nbsp;2025&nbsp;&nbsp;<a href="/list/">最新更新</a></p><p>请使用FDM BitComet qBittorrent uTorrent等BT下载工具，下载本站电子书资源！首推Free Download Manager下载软件。文件页数>标注页数[分册图书除外]</p></div></body></html>